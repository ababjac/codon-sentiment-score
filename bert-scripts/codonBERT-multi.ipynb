{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f15ec52-5086-48a9-aac4-aa843ad340bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "import helpers\n",
    "\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.nn import softmax\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoConfig\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, recall_score, accuracy_score, precision_score, multilabel_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7816c2e-0c38-41bb-86dc-e8bd22332440",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/lustre/isaac/proj/UTK0196/codon-expression-data/fullTableForTrainning/'\n",
    "RUN=1\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5c03270-8f7e-4889-8a8c-591701323d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(epred):\n",
    "    # Computes metrics from specialized output from huggingface\n",
    "    logits = epred[0]\n",
    "    probs = softmax(logits)\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    labels = epred[1]\n",
    "\n",
    "    metrics = {}\n",
    "    #metrics['auprc'] = average_precision_score(labels, preds[:,1])\n",
    "    metrics['auroc'] = roc_auc_score(labels, probs, multi_class='ovr', average='micro')\n",
    "    metrics['accuracy'] = SparseCategoricalAccuracy()(labels, logits)\n",
    "    metrics['precision'] = precision_score(labels, preds, average='micro')\n",
    "    metrics['recall'] = recall_score(labels, preds, average='micro')\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bb5674-c74a-4b12-b3c5-c58b08c074da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/isaac/scratch/ababjac/codon-sentiment-score/bert-scripts/helpers.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['codons_cleaned'] = get_codon_list(df[col])\n"
     ]
    }
   ],
   "source": [
    "print('Reading data...')\n",
    "filelist = os.listdir(PATH) \n",
    "df_list = [pd.read_csv(PATH+file) for file in filelist]\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "df = helpers.add_codons_to_df(df, 'Sequence')\n",
    "low, high = df.median_exp.quantile([0.33, 0.67])\n",
    "high_l = np.where(df['median_exp'] > high, 2, 0)\n",
    "low_l = np.where(df['median_exp'] > low, 0, 1)\n",
    "labels = high_l+low_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "553f9bb4-9883-48ff-a861-3f33576cd984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/63603 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7067 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classification_df = pd.DataFrame({'text' : df['codons_cleaned'], 'label' : labels})\n",
    "#MAX = int(max([(len(elem) / 3) for elem in df['codons_cleaned']])) #get max sequence length for padding\n",
    "#MED = int(np.median([(len(elem) / 3) for elem in df['codons_cleaned']])) #get median sequence length for padding\n",
    "\n",
    "#trunc_len = int((MAX + MED) / 2) #set truncation somewhere between max and median\n",
    "trunc_len=1024\n",
    "\n",
    "df_train, df_test = train_test_split(classification_df, test_size=0.001, random_state=1234)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.1, random_state=1234)\n",
    "\n",
    "del classification_df\n",
    "\n",
    "ds_train = Dataset.from_pandas(df_train)\n",
    "ds_val = Dataset.from_pandas(df_val)\n",
    "ds_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "del df_train\n",
    "del df_val\n",
    "del df_test\n",
    "\n",
    "print('Tokenizing...')\n",
    "config = AutoConfig.from_pretrained('distilbert-base-uncased', max_position_embeddings=trunc_len, num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained('../tokenizers/codonBERT', model_max_length=trunc_len, padding_side='left', truncation_side='right')\n",
    "\n",
    "tokenized_ds_train = ds_train.map(lambda d : tokenizer(d['text'], truncation=True, padding=True), batched=True)\n",
    "tokenized_ds_val = ds_val.map(lambda d : tokenizer(d['text'], truncation=True, padding=True), batched=True)\n",
    "tokenized_ds_test = ds_test.map(lambda d : tokenizer(d['text'], truncation=True, padding=True), batched=True)\n",
    "\n",
    "del ds_train\n",
    "del ds_val\n",
    "del ds_test\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f3b5adc-1d2f-49c4-84ea-4fdfc88bbff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('../models/codonBERT-multi_1/checkpoint-99500', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f14215f-8d85-48b2-aa00-d60b066853ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./models/codonBERT-multi_{}'.format(RUN),\n",
    "    learning_rate=2e-6,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds_train,\n",
    "    eval_dataset=tokenized_ds_val,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "597d6cfe-5dcf-4077-816d-34c824d7a147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = trainer.predict(test_dataset=tokenized_ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e3a2001-6548-4412-a7ea-1fbc0f5cac12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.5255616 ,  5.121209  , -3.4514704 ],\n",
       "       [-2.1221962 ,  3.222921  , -1.7396102 ],\n",
       "       [ 1.9877458 , -0.7484707 , -1.2706597 ],\n",
       "       [ 2.665568  , -0.97397494, -1.8267919 ],\n",
       "       [ 2.5613768 , -0.7155683 , -2.178398  ],\n",
       "       [-0.8920546 , -2.7351243 ,  2.9274845 ],\n",
       "       [ 0.7599996 , -0.4997601 , -0.10353538],\n",
       "       [ 4.082304  , -2.512336  , -2.126844  ],\n",
       "       [ 5.2003417 , -2.645346  , -2.6180964 ],\n",
       "       [-0.6895545 ,  3.3915231 , -3.2710204 ],\n",
       "       [ 1.2924222 ,  1.420453  , -4.0864916 ],\n",
       "       [ 0.5179515 , -1.2427034 ,  0.84787834],\n",
       "       [-4.1891    , -4.013499  ,  6.843054  ],\n",
       "       [-1.3392583 ,  2.9082913 , -1.9447596 ],\n",
       "       [-2.4363537 ,  5.179916  , -3.7035263 ],\n",
       "       [ 0.07737833, -0.14201617,  0.13429223],\n",
       "       [ 1.6633668 , -1.6811367 ,  0.24253425],\n",
       "       [-2.6283293 , -1.9312181 ,  3.8073454 ],\n",
       "       [ 3.7876704 , -1.9375799 , -2.237544  ],\n",
       "       [-3.2756495 , -2.7044613 ,  5.829259  ],\n",
       "       [-0.8586686 ,  2.7515242 , -2.0724301 ],\n",
       "       [-1.3800291 , -3.7836177 ,  3.8704877 ],\n",
       "       [-2.3437936 , -2.8229265 ,  4.7801085 ],\n",
       "       [ 1.467675  , -1.9707829 ,  0.8660606 ],\n",
       "       [ 2.2916522 , -0.3702455 , -1.734932  ],\n",
       "       [-2.5839803 ,  4.99495   , -3.1505527 ],\n",
       "       [ 3.0273144 , -0.38225213, -2.7448583 ],\n",
       "       [ 0.0782848 ,  1.2480133 , -1.7875738 ],\n",
       "       [ 3.6341736 , -1.2325139 , -2.1862898 ],\n",
       "       [ 2.5116918 , -0.74786747, -2.949734  ],\n",
       "       [ 1.6280318 , -0.64689535, -0.5866993 ],\n",
       "       [ 1.3895729 , -1.6228967 , -0.05916277],\n",
       "       [ 3.2813647 , -1.4643768 , -1.7965465 ],\n",
       "       [ 1.3176342 ,  1.2246428 , -2.021472  ],\n",
       "       [ 1.1813911 ,  1.4298577 , -3.2058542 ],\n",
       "       [ 0.71479803,  1.69436   , -2.538949  ],\n",
       "       [ 1.7424473 ,  0.8888253 , -2.3296275 ],\n",
       "       [ 1.2874216 ,  0.23954307, -2.5212605 ],\n",
       "       [-0.5057809 , -1.9725342 ,  2.4026856 ],\n",
       "       [-0.8383534 ,  2.2524993 , -1.180357  ],\n",
       "       [ 3.5267456 , -1.3040676 , -1.6357077 ],\n",
       "       [-2.3785255 ,  5.160724  , -3.2644346 ],\n",
       "       [ 2.0841532 , -1.7331952 , -0.08353048],\n",
       "       [ 0.13300519,  2.1785536 , -2.3981104 ],\n",
       "       [ 1.6339817 , -0.09117602, -1.2641771 ],\n",
       "       [ 2.0592003 , -1.9302776 ,  0.10810097],\n",
       "       [-2.4113598 , -4.6591616 ,  5.921679  ],\n",
       "       [ 2.9467528 , -1.4180459 , -1.8033335 ],\n",
       "       [ 1.1348251 ,  1.1174443 , -2.7270021 ],\n",
       "       [-1.8429321 ,  4.7720866 , -3.736154  ],\n",
       "       [ 3.8857017 , -0.9833216 , -3.3328338 ],\n",
       "       [-1.3046657 , -0.6518996 ,  2.059671  ],\n",
       "       [-0.1908855 ,  1.1551847 , -0.91807675],\n",
       "       [-0.26003274,  2.0350425 , -2.048127  ],\n",
       "       [ 2.6117485 , -0.21005037, -1.8452262 ],\n",
       "       [ 0.24690592,  0.6976742 , -0.76355004],\n",
       "       [-1.8529134 ,  3.7349536 , -2.2635806 ],\n",
       "       [ 5.206637  , -3.4783337 , -1.7499659 ],\n",
       "       [ 2.9374208 , -3.9740193 , -0.44445458],\n",
       "       [ 1.8589634 , -0.95383084, -0.89279574],\n",
       "       [ 3.7795713 , -1.3889921 , -2.6627188 ],\n",
       "       [ 2.5421526 , -1.0044241 , -0.9161395 ],\n",
       "       [-2.6688602 , -4.2314124 ,  5.6306515 ],\n",
       "       [ 2.9055068 , -0.69854474, -1.9877023 ],\n",
       "       [ 3.7366662 , -1.8827965 , -1.8594357 ],\n",
       "       [ 1.0122093 ,  1.4594164 , -2.0620065 ],\n",
       "       [ 3.6279056 , -1.2793255 , -2.6784766 ],\n",
       "       [ 2.1827538 , -1.308711  , -0.379804  ],\n",
       "       [-3.468314  , -4.010737  ,  6.2034636 ],\n",
       "       [-0.40731776,  3.3025348 , -3.138794  ],\n",
       "       [ 1.9980501 , -1.4154797 , -0.19933423]], dtype=float32), label_ids=array([1, 1, 0, 1, 0, 0, 2, 1, 2, 1, 1, 0, 2, 1, 1, 1, 0, 0, 0, 2, 0, 2,\n",
       "       0, 1, 0, 1, 0, 0, 0, 2, 0, 2, 1, 0, 1, 2, 1, 1, 2, 1, 2, 0, 2, 1,\n",
       "       0, 0, 2, 0, 1, 1, 1, 2, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 2, 0, 1, 1,\n",
       "       0, 1, 2, 2, 0]), metrics={'test_loss': 1.8319573402404785, 'test_runtime': 13.2261, 'test_samples_per_second': 5.368, 'test_steps_per_second': 1.361})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6037380-244f-436e-b6b9-f2e856cc15ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auroc': 0.70928387224757,\n",
       " 'accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.5492958>,\n",
       " 'precision': 0.5492957746478874,\n",
       " 'recall': 0.5492957746478874}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = compute_metrics(out)\n",
    "scores\n",
    "# with open('./results/codonBERT-multi_{}.txt'.format(RUN),'w') as data: \n",
    "#       data.write(str(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
